{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/home/palm/PycharmProjects/wordset-dictionary/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for file in os.listdir(json_path):\n",
    "    data.update(json.load(open(os.path.join(json_path, file))))\n",
    "keys = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'word': 'unsatisfactorily',\n",
       " 'wordset_id': '1e83c233b4',\n",
       " 'meanings': [{'id': '7bd00bab62',\n",
       "   'def': 'in an unsatisfactory manner',\n",
       "   'example': 'You performed unsatisfactorily as a manager.',\n",
       "   'speech_part': 'adverb'}],\n",
       " 'editors': ['bryanedu'],\n",
       " 'contributors': ['zellerpress', 'msingle', 'sabreuse']}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "key = keys[0]\n",
    "data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vocab, Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 108140/108140 [00:00<00:00, 305084.81lines/s]\n"
     ]
    }
   ],
   "source": [
    "counter = Counter()\n",
    "with tqdm(unit_scale=0, unit='lines', total=len(keys)) as t:\n",
    "    for key in keys:\n",
    "        word = data[key]\n",
    "        counter.update([key])\n",
    "        if 'meaning' in word:\n",
    "            for meaning in word['meanings']:\n",
    "                counter.update(meaning['def'].split(' '))\n",
    "        t.update(1)\n",
    "word_vocab = Vocab(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "108142"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "len(word_vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "word_vocab.freqs['analog']"
   ]
  },
  {
   "source": [
    "# the generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WordDataset(Dataset):\n",
    "    def __init__(self, json_path='/home/palm/PycharmProjects/wordset-dictionary/data/'):\n",
    "        self.json_path = json_path\n",
    "        counter = Counter()\n",
    "        self.data = []\n",
    "        for file in os.listdir(json_path):\n",
    "            data = json.load(open(os.path.join(json_path, file)))\n",
    "            for key in data:\n",
    "                word = data[key]\n",
    "                counter.update([key])\n",
    "                if 'meaning' in word:\n",
    "                    self.data.append(word)\n",
    "                    for meaning in word['meanings']:\n",
    "                        counter.update(meaning['def'].split(' '))\n",
    "        self.vocab = Vocab(counter)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        token_ids = list(filter(lambda x: x is not Vocab.UNK, [self.vocab[token]\n",
    "                                        for token in tokens]))\n",
    "        tokens = torch.tensor(token_ids)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = WordDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "t.data"
   ]
  }
 ]
}